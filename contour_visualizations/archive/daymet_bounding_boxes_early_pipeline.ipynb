{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################\n",
    "# Bounding boxes (improved) visualization logic - Hawaii region\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import fsspec\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12,8\n",
    "\n",
    "# !pip install opencv-python-headless\n",
    "import cv2\n",
    "from matplotlib.patches import Rectangle\n",
    "from typing import List, Tuple\n",
    "import itertools\n",
    "from copy import copy, deepcopy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import getpass\n",
    "import azure.storage.blob\n",
    "from azure.storage.blob import BlobClient, BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Draft pipeline to craeta bounding boxes. Processes by year.\n",
    "\n",
    "Input: the np arrays produced by the 1st process before this pipeline. These are the same size \n",
    "        arrays that have a heat event flag per iX,iY. But each location of unaware from each other. This\n",
    "        pipe aggregates them in x,y axeses first, then in time axis.\n",
    "Output: 3D Bounding boxes of all heat events.\n",
    "\"\"\"\n",
    "\n",
    "def bounding_boxes(arr2d: np.array) -> List[tuple]:\n",
    "    \n",
    "    H = arr2d.astype(np.uint8)\n",
    "    ret, thresh = cv2.threshold(H, 0, 1, 0, cv2.THRESH_BINARY)\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = [cv2.boundingRect(c) for c in contours]\n",
    "    return boxes\n",
    "\n",
    "def isoverlap(box1:tuple, box2:tuple) -> bool:\n",
    "    \"\"\"Return True if two windows overlap\"\"\"\n",
    "    x1,y1,w1,h1 = box1\n",
    "    x2,y2,w2,h2 = box2\n",
    "    return not (x2>x1+w1 or x2+w2<x1 or y2>y1+h1 or y2+h2<y1)\n",
    "\n",
    "def outer(box1:tuple, box2:tuple) -> tuple:\n",
    "    \"\"\"Fuse two windows into one, parent window.\"\"\"\n",
    "    x1,y1,w1,h1 = box1\n",
    "    x2,y2,w2,h2 = box2\n",
    "    x = min(x1,x2)\n",
    "    y = min(y1,y2)\n",
    "    w = max(x1+w1,x2+w2)-x\n",
    "    h = max(y1+h1,y2+h2)-y\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def istiny(box:tuple, min_area:int) -> bool:\n",
    "    x,y,w,h = box\n",
    "    return w*h <= min_area\n",
    "\n",
    "def filter_tiny_ones(boxes:List[tuple]) -> List[tuple]:\n",
    "    return [c for c in boxes if not istiny(c, 10)]\n",
    "\n",
    "def collapse(boxes:List[tuple]) -> List[tuple]:\n",
    "    \n",
    "    for box1, box2 in itertools.combinations(boxes, 2):\n",
    "        if isoverlap(box1,box2):\n",
    "            boxes.remove(box1)\n",
    "            boxes.remove(box2)\n",
    "            boxes.append(outer(box1,box2))\n",
    "            return collapse(boxes) # recursion\n",
    "\n",
    "    boxes.sort(key=lambda _:_[0])\n",
    "    return boxes\n",
    "\n",
    "def array2boxes(arr2d:np.array) -> List[tuple]:\n",
    "    \"\"\"Pipeline. Takes a time-slice (2D array) and returns the boxes.\"\"\"\n",
    "    boxes = bounding_boxes(arr2d)\n",
    "    boxes = filter_tiny_ones(boxes)\n",
    "    boxes = collapse(boxes)\n",
    "    return boxes\n",
    "\n",
    "def groupby_heat_events(arr3d:np.array) -> List[dict]:\n",
    "    rows = []\n",
    "    num_days = arr3d.shape[0]\n",
    "\n",
    "    for i in range(num_days):\n",
    "        arr2d = arr3d[i,:,:]\n",
    "        boxes = array2boxes(arr2d)\n",
    "        rows += [dict(time=i, boxes=boxes)]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['hasEvent'] = df['boxes'].apply(lambda x: len(x)) > 0\n",
    "    df['label'] = df['hasEvent'].diff().ne(False).cumsum()\n",
    "\n",
    "    dff = df[df['hasEvent']]\n",
    "\n",
    "    dfg = dff.groupby('label').agg({\n",
    "        'time':[np.min,np.max], \n",
    "        'boxes':lambda _: collapse(np.sum(_))\n",
    "    }).reset_index()\n",
    "    dfg.columns = ['label', 'i1', 'i2', 'boxes']\n",
    "    dfg = dfg.assign(d1=dr[dfg['i1']], d2=dr[dfg['i2']])\n",
    "    dfg = dfg.drop('label', axis=1)\n",
    "    \n",
    "    return dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "        20, 23]),\n",
       " array([6544, 2986, 1067,  903,  445,  483,  447,  175,   61,   38,   26,\n",
       "          16,    7,    7,    6,    6,    1,    1,    1]))"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "year = 1971\n",
    "dr = pd.date_range(start=f'1/1/{year}', periods=365, freq='D').date\n",
    "arr3d = np.load(f'Koray/CMIP5_flagged/arr_heat3d-{year}.npy')\n",
    "\n",
    "df_events = groupby_heat_events(arr3d)\n",
    "\n",
    "# e.g. there is a heat wave that took 23 days!\n",
    "np.unique(np.unique(arr3d[np.where(arr3d>0)], return_counts=True)[1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Azure access\n",
    "sas_token = getpass.getpass() \n",
    "url_prefix = 'https://nexdcp30.blob.core.windows.net'\n",
    "blob_folder = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### INPUTS ######################\n",
    "lat_min = 0   \n",
    "lat_max = 50  \n",
    "lon_min = 220 \n",
    "lon_max = 300 \n",
    "############################################# \n",
    "\n",
    "area = dict(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "\n",
    "# temp data\n",
    "ds = xr.open_mfdataset('Koray/CMIP5/*.nc')\n",
    "\n",
    "# Ravi's avg \n",
    "ds_avg = xr.open_dataset(\"Avg_temp_max_CMIP5__30_yrs__1950_to_1979.nc\")\n",
    "\n",
    "\n",
    "for year in range(1970,1980):\n",
    "\n",
    "    dr = pd.date_range(start=f'1/1/{year}', periods=365, freq='D').date\n",
    "    arr3d = np.load(f'Koray/CMIP5_flagged/arr_heat3d-{year}.npy') # must be ready\n",
    "    df_events = groupby_heat_events(arr3d)\n",
    "\n",
    "    for ev, (i1, i2) in df_events[['i1','i2']].iterrows():\n",
    "        # to write the image to disk\n",
    "        folder_name = f\"{year}-event{str(ev).zfill(2)}\"\n",
    "        folder_path = f\"Koray/CMIP5_images/{folder_name}\"\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "        \n",
    "        # loop through heat events, some are 3 days long, some are 20\n",
    "        for i, idx in enumerate(range(i1,i2+1)):\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\n",
    "\n",
    "            day = dr[idx].strftime(\"%Y-%m-%d\")\n",
    "            tasmax = ds['tasmax'].sel(time=day, **area)\n",
    "            tavg3d = ds_avg['tasmaxavg'].sel(day=idx, **area)\n",
    "            tdiff = tasmax - tavg3d\n",
    "\n",
    "            im1 = tdiff.squeeze().plot.imshow(ax=ax1, cmap='Reds', vmin=-4, vmax=4)\n",
    "            im2 = (tasmax-273.15).squeeze().plot.imshow(ax=ax2, vmin=5, vmax=50)\n",
    "\n",
    "            # add bounding boxes\n",
    "            boxes = df_events['boxes'].iloc[ev]\n",
    "            for b in boxes:\n",
    "                x,y,w,h = b\n",
    "                x = float(tdiff.coords['lon'][x])\n",
    "                y = float(tdiff.coords['lat'][y])\n",
    "                _, leny, lenx = tdiff.shape\n",
    "\n",
    "                w = w * (lon_max-lon_min) / lenx\n",
    "                h = h * (lat_max-lat_min) / leny \n",
    "\n",
    "                rect = Rectangle((x, y), w, h, color='b', fill=False, linewidth=2)\n",
    "                ax1.add_patch(rect)\n",
    "                rect = Rectangle((x, y), w, h, color='b', fill=False, linewidth=2)\n",
    "                ax2.add_patch(rect)\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # save each image, each event has multiple images, one per event day.\n",
    "            filename = f\"{folder_path}/{day}.png\"\n",
    "            fig.savefig(filename, dpi=fig.dpi)\n",
    "            plt.close(fig)\n",
    "\n",
    "            # upload image to azure\n",
    "            sas_url = f\"{url_prefix}/{blob_folder}/{filename}?{sas_token}\"\n",
    "            blob_client = BlobClient.from_blob_url(sas_url)\n",
    "            with open(filename, \"rb\") as f:\n",
    "                try:\n",
    "                    blob_client.upload_blob(f)\n",
    "                except ResourceExistsError:\n",
    "                    pass\n",
    "    \n",
    "        # flush VM disk space\n",
    "        shutil.rmtree(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
